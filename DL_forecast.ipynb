{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_forecast.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXecJ7F5Di6"
      },
      "source": [
        "# Import and install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv1dxq0FtmAQ"
      },
      "source": [
        "!pip install yfinance --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBKRzlw2snPB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGCEkgS-5Gwz"
      },
      "source": [
        "# Prepare Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JDBv2n95tnxn",
        "outputId": "6940dbed-cdcd-4cfe-cbc3-a5164b2d265d"
      },
      "source": [
        "data = yf.Ticker('TSLA')\n",
        "data = data.history(start=\"2020-12-31\", interval='1d', rounding=True)\n",
        "data = data[['Close']].reset_index()\n",
        "\n",
        "r = pd.date_range(start=data.Date.min(), end=pd.to_datetime(data.Date.max(), format='%Y-%m-%d'))\n",
        "data=data.groupby('Date').mean().reindex(r)\n",
        "data.fillna(method='ffill',inplace=True)\n",
        "data = data.reset_index().rename({'index':'Date'},axis=1)\n",
        "data = data.loc[data.Date >= '2021-01-01']\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>705.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-02</td>\n",
              "      <td>705.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-03</td>\n",
              "      <td>705.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>729.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-01-05</td>\n",
              "      <td>735.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>2021-09-17</td>\n",
              "      <td>759.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>2021-09-18</td>\n",
              "      <td>759.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>2021-09-19</td>\n",
              "      <td>759.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>2021-09-20</td>\n",
              "      <td>730.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>2021-09-21</td>\n",
              "      <td>739.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date   Close\n",
              "1   2021-01-01  705.67\n",
              "2   2021-01-02  705.67\n",
              "3   2021-01-03  705.67\n",
              "4   2021-01-04  729.77\n",
              "5   2021-01-05  735.11\n",
              "..         ...     ...\n",
              "260 2021-09-17  759.49\n",
              "261 2021-09-18  759.49\n",
              "262 2021-09-19  759.49\n",
              "263 2021-09-20  730.17\n",
              "264 2021-09-21  739.38\n",
              "\n",
              "[264 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gc-70NTRb1b"
      },
      "source": [
        "def scale_tesla(data):\n",
        "  return (data - 550)/(900-550)\n",
        "def scale_tesla_inv(data):\n",
        "  return data*(900-550) + 550"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIMNb3N1Q9k7"
      },
      "source": [
        "data['Close'] = data.Close.apply(scale_tesla)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AI9qXcyeD-ic",
        "outputId": "e99159ca-a83e-45af-e21f-73f72be622be"
      },
      "source": [
        "#scaler  = MinMaxScaler()\n",
        "#scaler.fit(data.Close.to_numpy()[:,np.newaxis])\n",
        "#data['Close'] = scaler.transform(data.Close.to_numpy()[:,np.newaxis])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>0.444771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-02</td>\n",
              "      <td>0.444771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-03</td>\n",
              "      <td>0.444771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>0.513629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-01-05</td>\n",
              "      <td>0.528886</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date     Close\n",
              "1 2021-01-01  0.444771\n",
              "2 2021-01-02  0.444771\n",
              "3 2021-01-03  0.444771\n",
              "4 2021-01-04  0.513629\n",
              "5 2021-01-05  0.528886"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmIqbFBGveeX"
      },
      "source": [
        "elon = pd.read_csv('/content/drive/MyDrive/Assignments/Stock price/Models_TS/elon_sent_2021.csv',index_col=0)\n",
        "reddit = pd.read_csv('/content/drive/MyDrive/Assignments/Stock price/Models_TS/reddit_sent_2021.csv',index_col=0)\n",
        "reddit.fillna(0,inplace=True)\n",
        "news = pd.read_csv('/content/drive/MyDrive/Assignments/Stock price/Models_TS/news_sent_2021.csv',index_col=0)\n",
        "news['date'] = pd.to_datetime(news.date,format='%d/%m/%Y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg_zv2Gi5sF4",
        "outputId": "68ba9d29-4c68-4b20-9abb-9675f984f982"
      },
      "source": [
        "print(data.shape,data.Date.min(),data.Date.max())\n",
        "print(elon.shape,elon.date.min(),elon.date.max())\n",
        "print(reddit.shape,reddit.date.min(),reddit.date.max())\n",
        "print(news.shape,news.date.min(),news.date.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(264, 2) 2021-01-01 00:00:00 2021-09-21 00:00:00\n",
            "(262, 2) 2021-01-01 2021-09-19\n",
            "(259, 2) 2021-01-01 2021-09-16\n",
            "(262, 2) 2021-01-01 00:00:00 2021-09-19 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGuEByak6yQG"
      },
      "source": [
        "data = data[:259]\n",
        "elon = elon[:259]\n",
        "reddit = reddit[:259]\n",
        "news =  news[:259]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDRQv65v7D09",
        "outputId": "0804d492-fd61-49b2-e788-011f4fdd70af"
      },
      "source": [
        "print(data.shape,data.Date.min(),data.Date.max())\n",
        "print(elon.shape,elon.date.min(),elon.date.max())\n",
        "print(reddit.shape,reddit.date.min(),reddit.date.max())\n",
        "print(news.shape,news.date.min(),news.date.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259, 2) 2021-01-01 00:00:00 2021-09-16 00:00:00\n",
            "(259, 2) 2021-01-01 2021-09-16\n",
            "(259, 2) 2021-01-01 2021-09-16\n",
            "(259, 2) 2021-01-01 00:00:00 2021-09-16 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5WP9Tf-Q70F8",
        "outputId": "497b6cfc-0fd3-4560-cb8a-103a09a30655"
      },
      "source": [
        "data = pd.DataFrame({'stock':data.Close.values,'elon':elon.sentiment.values,'reddit':reddit.sentiment.values,'news':news.sentiment.values})\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>elon</th>\n",
              "      <th>reddit</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.506010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.397090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.375703</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.513629</td>\n",
              "      <td>-0.036051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.233317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.528886</td>\n",
              "      <td>0.067608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>0.532200</td>\n",
              "      <td>0.069704</td>\n",
              "      <td>-0.026345</td>\n",
              "      <td>0.237941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.551429</td>\n",
              "      <td>-0.072337</td>\n",
              "      <td>0.011645</td>\n",
              "      <td>0.765736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.555686</td>\n",
              "      <td>0.002163</td>\n",
              "      <td>-0.081138</td>\n",
              "      <td>-0.156679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.588086</td>\n",
              "      <td>0.310431</td>\n",
              "      <td>-0.069122</td>\n",
              "      <td>-0.293066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.591400</td>\n",
              "      <td>0.759627</td>\n",
              "      <td>0.011083</td>\n",
              "      <td>-0.429454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>259 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        stock      elon    reddit      news\n",
              "0    0.444771  0.506010  0.000000  0.366396\n",
              "1    0.444771  0.397090  0.000000  0.149246\n",
              "2    0.444771  0.375703  0.000000  0.248707\n",
              "3    0.513629 -0.036051  0.000000 -0.233317\n",
              "4    0.528886  0.067608  0.000000  0.020349\n",
              "..        ...       ...       ...       ...\n",
              "254  0.532200  0.069704 -0.026345  0.237941\n",
              "255  0.551429 -0.072337  0.011645  0.765736\n",
              "256  0.555686  0.002163 -0.081138 -0.156679\n",
              "257  0.588086  0.310431 -0.069122 -0.293066\n",
              "258  0.591400  0.759627  0.011083 -0.429454\n",
              "\n",
              "[259 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i064wp6-8dt1",
        "outputId": "8310565f-e254-4b5e-ec91-e9b3c92168a2"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stock     0\n",
              "elon      0\n",
              "reddit    0\n",
              "news      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaTIyZqfOWEz"
      },
      "source": [
        "scaler  = MinMaxScaler()\n",
        "scaler.fit(data.iloc[:,1:].to_numpy())\n",
        "data.iloc[:,1:] = scaler.transform(data.iloc[:,1:].to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iZaIpJzy8tH1",
        "outputId": "b6e87b8d-f53b-4848-edef-83f748566922"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>elon</th>\n",
              "      <th>reddit</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.721979</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.702044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.659272</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.587116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.444771</td>\n",
              "      <td>0.646959</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.639756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.513629</td>\n",
              "      <td>0.409908</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.384641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.528886</td>\n",
              "      <td>0.469586</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.518895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>0.532200</td>\n",
              "      <td>0.470792</td>\n",
              "      <td>0.330724</td>\n",
              "      <td>0.634058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.551429</td>\n",
              "      <td>0.389017</td>\n",
              "      <td>0.505636</td>\n",
              "      <td>0.913398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.555686</td>\n",
              "      <td>0.431908</td>\n",
              "      <td>0.078441</td>\n",
              "      <td>0.425202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.588086</td>\n",
              "      <td>0.609382</td>\n",
              "      <td>0.133764</td>\n",
              "      <td>0.353018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.591400</td>\n",
              "      <td>0.867989</td>\n",
              "      <td>0.503048</td>\n",
              "      <td>0.280834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>259 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        stock      elon    reddit      news\n",
              "0    0.444771  0.721979  0.452021  0.702044\n",
              "1    0.444771  0.659272  0.452021  0.587116\n",
              "2    0.444771  0.646959  0.452021  0.639756\n",
              "3    0.513629  0.409908  0.452021  0.384641\n",
              "4    0.528886  0.469586  0.452021  0.518895\n",
              "..        ...       ...       ...       ...\n",
              "254  0.532200  0.470792  0.330724  0.634058\n",
              "255  0.551429  0.389017  0.505636  0.913398\n",
              "256  0.555686  0.431908  0.078441  0.425202\n",
              "257  0.588086  0.609382  0.133764  0.353018\n",
              "258  0.591400  0.867989  0.503048  0.280834\n",
              "\n",
              "[259 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B06YGBe9UDF"
      },
      "source": [
        "# Create windows for tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rU7oz6r94T-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfvb4HIg9S5H"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "\n",
        "dataset = dataset.window(28, shift=1, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.flat_map(lambda w: w.batch(28))\n",
        "\n",
        "dataset = dataset.map(lambda w: (w[:21], w[21:,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xw1b9EkBVUI",
        "outputId": "4f997cf6-e382-4e09-d5ef-9d6ec89a0157"
      },
      "source": [
        "size = sum(1 for X,y in dataset)\n",
        "for X, y in dataset.take(1):\n",
        "  print(\"Input:\", X.numpy(), \"Target:\", y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [[0.44477143 0.72197878 0.452021   0.70204426]\n",
            " [0.44477143 0.65927193 0.452021   0.58711558]\n",
            " [0.44477143 0.64695935 0.452021   0.63975636]\n",
            " [0.51362857 0.40990793 0.452021   0.38464059]\n",
            " [0.52888571 0.46958577 0.452021   0.5188954 ]\n",
            " [0.58851429 0.4701776  0.452021   0.32040764]\n",
            " [0.76011429 0.47076943 0.452021   0.50533557]\n",
            " [0.94291429 0.58243387 0.452021   0.60502952]\n",
            " [0.94291429 0.62863436 0.452021   0.60442066]\n",
            " [0.94291429 0.45548311 0.452021   0.5059418 ]\n",
            " [0.74625714 0.57413146 0.452021   0.45069572]\n",
            " [0.85554286 0.59005811 0.452021   0.6089151 ]\n",
            " [0.86974286 0.47683708 0.452021   0.47929249]\n",
            " [0.84285714 0.36361604 0.452021   0.41527245]\n",
            " [0.78902857 0.63001946 0.452021   0.5096471 ]\n",
            " [0.78902857 0.56157798 0.452021   0.94105479]\n",
            " [0.78902857 0.99146735 0.452021   0.72642916]\n",
            " [0.78902857 0.63290191 0.452021   0.0086692 ]\n",
            " [0.84157143 0.81645095 0.452021   0.0086692 ]\n",
            " [0.85842857 1.         0.452021   0.18253416]\n",
            " [0.84282857 0.60761825 0.452021   0.35639912]] Target: [0.84754286 0.84754286 0.84754286 0.94514286 0.95168571 0.8976\n",
            " 0.81551429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wBAA_S7EDkP"
      },
      "source": [
        "train_dataset = dataset.take(size).shuffle(10).batch(8).prefetch(1)\n",
        "test_dataset = dataset.skip(size-7).batch(8).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXd0p1CEp5H",
        "outputId": "8defde27-b3be-4028-8678-555974154663"
      },
      "source": [
        "for i,j in test_dataset:\n",
        "  print(i,j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[0.47762857 0.59172947 0.51151479 0.01280433]\n",
            "  [0.47762857 0.49703976 0.47893533 0.5202217 ]\n",
            "  [0.38905714 0.99135625 0.16831186 0.44170826]\n",
            "  [0.3306     0.9824216  0.14537593 0.44987195]\n",
            "  [0.39711429 0.54655532 0.33530191 0.41112763]\n",
            "  [0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]]\n",
            "\n",
            " [[0.47762857 0.49703976 0.47893533 0.5202217 ]\n",
            "  [0.38905714 0.99135625 0.16831186 0.44170826]\n",
            "  [0.3306     0.9824216  0.14537593 0.44987195]\n",
            "  [0.39711429 0.54655532 0.33530191 0.41112763]\n",
            "  [0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]]\n",
            "\n",
            " [[0.38905714 0.99135625 0.16831186 0.44170826]\n",
            "  [0.3306     0.9824216  0.14537593 0.44987195]\n",
            "  [0.39711429 0.54655532 0.33530191 0.41112763]\n",
            "  [0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]\n",
            "  [0.52448571 0.61293262 0.33033414 0.52036902]]\n",
            "\n",
            " [[0.3306     0.9824216  0.14537593 0.44987195]\n",
            "  [0.39711429 0.54655532 0.33530191 0.41112763]\n",
            "  [0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]\n",
            "  [0.52448571 0.61293262 0.33033414 0.52036902]\n",
            "  [0.52448571 0.5796998  0.38719257 0.60951181]]\n",
            "\n",
            " [[0.39711429 0.54655532 0.33530191 0.41112763]\n",
            "  [0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]\n",
            "  [0.52448571 0.61293262 0.33033414 0.52036902]\n",
            "  [0.52448571 0.5796998  0.38719257 0.60951181]\n",
            "  [0.57977143 0.55798512 0.35172091 0.6986546 ]]\n",
            "\n",
            " [[0.35277143 0.95511286 0.36936832 0.61868594]\n",
            "  [0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]\n",
            "  [0.52448571 0.61293262 0.33033414 0.52036902]\n",
            "  [0.52448571 0.5796998  0.38719257 0.60951181]\n",
            "  [0.57977143 0.55798512 0.35172091 0.6986546 ]\n",
            "  [0.58248571 0.53627043 0.18757158 0.64492141]]\n",
            "\n",
            " [[0.37217143 0.48108422 1.         0.48399122]\n",
            "  [0.37217143 0.68587495 0.24470579 0.48399122]\n",
            "  [0.37217143 0.57799265 0.39711424 0.62959127]\n",
            "  [0.44657143 0.47011035 0.2603303  0.62959127]\n",
            "  [0.45282857 0.61038944 0.41849211 0.64609504]\n",
            "  [0.46057143 0.5828189  0.48530384 0.46398261]\n",
            "  [0.43188571 0.53718406 0.37104129 0.25046064]\n",
            "  [0.46262857 0.67840122 0.65321072 0.48324325]\n",
            "  [0.46262857 0.46205261 0.17870315 0.44847029]\n",
            "  [0.46262857 0.52849103 0.12589763 0.0073266 ]\n",
            "  [0.51688571 0.62494266 0.42756703 0.57147175]\n",
            "  [0.53062857 0.39952733 0.23371142 0.27300218]\n",
            "  [0.52597143 0.46743511 0.55351344 0.59769174]\n",
            "  [0.52111429 0.56625441 0.44557085 0.25832078]\n",
            "  [0.52448571 0.44921049 0.22645945 0.52022226]\n",
            "  [0.52448571 0.64616545 0.34330745 0.54476765]\n",
            "  [0.52448571 0.61293262 0.33033414 0.52036902]\n",
            "  [0.52448571 0.5796998  0.38719257 0.60951181]\n",
            "  [0.57977143 0.55798512 0.35172091 0.6986546 ]\n",
            "  [0.58248571 0.53627043 0.18757158 0.64492141]\n",
            "  [0.58531429 0.47290986 0.35644978 0.59118821]]], shape=(7, 21, 4), dtype=float64) tf.Tensor(\n",
            "[[0.52448571 0.52448571 0.52448571 0.57977143 0.58248571 0.58531429\n",
            "  0.5322    ]\n",
            " [0.52448571 0.52448571 0.57977143 0.58248571 0.58531429 0.5322\n",
            "  0.5322    ]\n",
            " [0.52448571 0.57977143 0.58248571 0.58531429 0.5322     0.5322\n",
            "  0.5322    ]\n",
            " [0.57977143 0.58248571 0.58531429 0.5322     0.5322     0.5322\n",
            "  0.55142857]\n",
            " [0.58248571 0.58531429 0.5322     0.5322     0.5322     0.55142857\n",
            "  0.55568571]\n",
            " [0.58531429 0.5322     0.5322     0.5322     0.55142857 0.55568571\n",
            "  0.58808571]\n",
            " [0.5322     0.5322     0.5322     0.55142857 0.55568571 0.58808571\n",
            "  0.5914    ]], shape=(7, 7), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMrqoTreJPjY"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFzvzVaUFo8O"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, LSTM, GRU\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1YEiUCfJaXQ",
        "outputId": "2c5ac884-a934-45be-9dff-7e0f0bbc2d8b"
      },
      "source": [
        "model1 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    LSTM(60, return_sequences=True),\n",
        "    LSTM(60, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(60, activation=\"relu\"),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dropout(0.4),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model2 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    LSTM(60, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(60, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model3 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(60, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model4 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    LSTM(80, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(600, activation=\"relu\"),\n",
        "    Dense(120, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model5 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    LSTM(80, return_sequences=True),\n",
        "    GRU(80, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(600, activation=\"relu\"),\n",
        "    Dense(120, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model6 = Sequential([\n",
        "    Input(shape=(21,4)),\n",
        "    #Model layers\n",
        "    GRU(80, return_sequences=True),\n",
        "    Flatten(),\n",
        "    Dense(600, activation=\"relu\"),\n",
        "    Dense(120, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(7)\n",
        "])\n",
        "\n",
        "model = model6\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_5 (GRU)                  (None, 21, 80)            20640     \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 1680)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 600)               1008600   \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 120)               72120     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 16)                1936      \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 7)                 119       \n",
            "=================================================================\n",
            "Total params: 1,103,415\n",
            "Trainable params: 1,103,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5dicBeDJuX2"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    metrics=['mae'],\n",
        ")\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
        "    patience=100, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"loss\",\n",
        ")\n",
        "\n",
        "reduceLR = callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"loss\",\n",
        "    factor=0.1,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=25\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x117GdhvKKPn",
        "outputId": "74b9011a-4e05-44f5-8fc5-cbe28decd8a7"
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    batch_size = 8,\n",
        "    epochs=500,\n",
        "    callbacks=[early_stopping, reduceLR]\n",
        ")\n",
        "\n",
        "history_frame = pd.DataFrame(history.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "29/29 [==============================] - 3s 10ms/step - loss: 0.0567 - mae: 0.2487\n",
            "Epoch 2/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0300 - mae: 0.1926\n",
            "Epoch 3/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0251 - mae: 0.1714\n",
            "Epoch 4/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0217 - mae: 0.1590\n",
            "Epoch 5/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0202 - mae: 0.1650\n",
            "Epoch 6/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1493\n",
            "Epoch 7/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0266 - mae: 0.1664\n",
            "Epoch 8/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.1353\n",
            "Epoch 9/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0245 - mae: 0.1799\n",
            "Epoch 10/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0164 - mae: 0.1541\n",
            "Epoch 11/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1360\n",
            "Epoch 12/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0089 - mae: 0.1115\n",
            "Epoch 13/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0082 - mae: 0.1053\n",
            "Epoch 14/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0063 - mae: 0.0932\n",
            "Epoch 15/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0056 - mae: 0.0865\n",
            "Epoch 16/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0848\n",
            "Epoch 17/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0059 - mae: 0.0897\n",
            "Epoch 18/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0877\n",
            "Epoch 19/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0768\n",
            "Epoch 20/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0735\n",
            "Epoch 21/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0701\n",
            "Epoch 22/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0035 - mae: 0.0676\n",
            "Epoch 23/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - mae: 0.0609\n",
            "Epoch 24/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0033 - mae: 0.0636\n",
            "Epoch 25/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0746\n",
            "Epoch 26/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0828\n",
            "Epoch 27/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0056 - mae: 0.0786\n",
            "Epoch 28/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0755\n",
            "Epoch 29/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0065 - mae: 0.0915\n",
            "Epoch 30/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0076 - mae: 0.0982\n",
            "Epoch 31/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0928\n",
            "Epoch 32/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0085 - mae: 0.1064\n",
            "Epoch 33/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0081 - mae: 0.1008\n",
            "Epoch 34/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1257\n",
            "Epoch 35/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0094 - mae: 0.1092\n",
            "Epoch 36/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0071 - mae: 0.1014\n",
            "Epoch 37/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0077 - mae: 0.0973\n",
            "Epoch 38/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0931\n",
            "Epoch 39/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1194\n",
            "Epoch 40/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1236\n",
            "Epoch 41/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0890\n",
            "Epoch 42/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0038 - mae: 0.0697\n",
            "Epoch 43/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0033 - mae: 0.0640\n",
            "Epoch 44/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0029 - mae: 0.0586\n",
            "Epoch 45/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0523\n",
            "Epoch 46/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0021 - mae: 0.0509\n",
            "Epoch 47/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0021 - mae: 0.0490\n",
            "Epoch 48/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0477\n",
            "Epoch 49/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0463\n",
            "Epoch 50/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0461\n",
            "Epoch 51/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0461\n",
            "Epoch 52/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0450\n",
            "Epoch 53/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0021 - mae: 0.0483\n",
            "Epoch 54/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0026 - mae: 0.0580\n",
            "Epoch 55/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0432\n",
            "Epoch 56/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0467\n",
            "Epoch 57/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0466\n",
            "Epoch 58/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - mae: 0.0427\n",
            "Epoch 59/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0396\n",
            "Epoch 60/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0383\n",
            "Epoch 61/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0344\n",
            "Epoch 62/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0334\n",
            "Epoch 63/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0334\n",
            "Epoch 64/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0353\n",
            "Epoch 65/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0366\n",
            "Epoch 66/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - mae: 0.0385\n",
            "Epoch 67/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - mae: 0.0420\n",
            "Epoch 68/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0393\n",
            "Epoch 69/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0381\n",
            "Epoch 70/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - mae: 0.0427\n",
            "Epoch 71/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0459\n",
            "Epoch 72/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0371\n",
            "Epoch 73/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0347\n",
            "Epoch 74/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0364\n",
            "Epoch 75/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.7583e-04 - mae: 0.0322\n",
            "Epoch 76/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0393\n",
            "Epoch 77/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0361\n",
            "Epoch 78/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0377\n",
            "Epoch 79/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0383\n",
            "Epoch 80/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0022 - mae: 0.0509\n",
            "Epoch 81/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0028 - mae: 0.0571\n",
            "Epoch 82/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0035 - mae: 0.0646\n",
            "Epoch 83/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0027 - mae: 0.0554\n",
            "Epoch 84/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0026 - mae: 0.0550\n",
            "Epoch 85/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0034 - mae: 0.0620\n",
            "Epoch 86/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0025 - mae: 0.0530\n",
            "Epoch 87/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0482\n",
            "Epoch 88/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0524\n",
            "Epoch 89/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0446\n",
            "Epoch 90/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0379\n",
            "Epoch 91/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - mae: 0.0384\n",
            "Epoch 92/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.6179e-04 - mae: 0.0313\n",
            "Epoch 93/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0390\n",
            "Epoch 94/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.6312e-04 - mae: 0.0326\n",
            "Epoch 95/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.3878e-04 - mae: 0.0328\n",
            "Epoch 96/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0360\n",
            "Epoch 97/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0475\n",
            "Epoch 98/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0455\n",
            "Epoch 99/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - mae: 0.0348\n",
            "Epoch 100/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0349\n",
            "Epoch 101/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.7084e-04 - mae: 0.0320\n",
            "Epoch 102/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0347\n",
            "Epoch 103/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - mae: 0.0391\n",
            "Epoch 104/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0333\n",
            "Epoch 105/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.3089e-04 - mae: 0.0293\n",
            "Epoch 106/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0363\n",
            "Epoch 107/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0339\n",
            "Epoch 108/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.6951e-04 - mae: 0.0320\n",
            "Epoch 109/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.9314e-04 - mae: 0.0306\n",
            "Epoch 110/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0010 - mae: 0.0329\n",
            "Epoch 111/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.1923e-04 - mae: 0.0317\n",
            "Epoch 112/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.7907e-04 - mae: 0.0322\n",
            "Epoch 113/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.6055e-04 - mae: 0.0296\n",
            "Epoch 114/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.0713e-04 - mae: 0.0316\n",
            "Epoch 115/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.2656e-04 - mae: 0.0297\n",
            "Epoch 116/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 7.3928e-04 - mae: 0.0278\n",
            "Epoch 117/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0321\n",
            "Epoch 118/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 7.0467e-04 - mae: 0.0276\n",
            "Epoch 119/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.2148e-04 - mae: 0.0329\n",
            "Epoch 120/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.8333e-04 - mae: 0.0321\n",
            "Epoch 121/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.3544e-04 - mae: 0.0318\n",
            "Epoch 122/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0407\n",
            "Epoch 123/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0376\n",
            "Epoch 124/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - mae: 0.0348\n",
            "Epoch 125/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0343\n",
            "Epoch 126/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 9.4720e-04 - mae: 0.0318\n",
            "Epoch 127/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0451\n",
            "Epoch 128/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0390\n",
            "Epoch 129/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0698\n",
            "Epoch 130/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0026 - mae: 0.0567\n",
            "Epoch 131/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - mae: 0.0443\n",
            "Epoch 132/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0031 - mae: 0.0585\n",
            "Epoch 133/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0458\n",
            "Epoch 134/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0027 - mae: 0.0541\n",
            "Epoch 135/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0021 - mae: 0.0500\n",
            "Epoch 136/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0020 - mae: 0.0486\n",
            "Epoch 137/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - mae: 0.0436\n",
            "Epoch 138/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0025 - mae: 0.0547\n",
            "Epoch 139/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0495\n",
            "Epoch 140/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0021 - mae: 0.0482\n",
            "Epoch 141/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0013 - mae: 0.0388\n",
            "Epoch 142/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0023 - mae: 0.0530\n",
            "Epoch 143/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - mae: 0.0437\n",
            "Epoch 144/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - mae: 0.0349\n",
            "Epoch 145/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0379\n",
            "Epoch 146/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0464\n",
            "Epoch 147/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0360\n",
            "Epoch 148/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - mae: 0.0383\n",
            "Epoch 149/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.3485e-04 - mae: 0.0312\n",
            "Epoch 150/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0353\n",
            "Epoch 151/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.3753e-04 - mae: 0.0311\n",
            "Epoch 152/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0018 - mae: 0.0436\n",
            "Epoch 153/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.7844e-04 - mae: 0.0337\n",
            "Epoch 154/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0443\n",
            "Epoch 155/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.0014 - mae: 0.0388\n",
            "Epoch 156/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.3634e-04 - mae: 0.0305\n",
            "Epoch 157/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.2279e-04 - mae: 0.0319\n",
            "Epoch 158/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.6392e-04 - mae: 0.0328\n",
            "Epoch 159/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - mae: 0.0359\n",
            "Epoch 160/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 7.3154e-04 - mae: 0.0277\n",
            "Epoch 161/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.9805e-04 - mae: 0.0347\n",
            "Epoch 162/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - mae: 0.0473\n",
            "Epoch 163/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - mae: 0.0419\n",
            "Epoch 164/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0426\n",
            "Epoch 165/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 8.7310e-04 - mae: 0.0320\n",
            "Epoch 166/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 9.3302e-04 - mae: 0.0334\n",
            "\n",
            "Epoch 00166: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 167/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - mae: 0.0356\n",
            "Epoch 168/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 5.2069e-04 - mae: 0.0238\n",
            "Epoch 169/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 4.5626e-04 - mae: 0.0222\n",
            "Epoch 170/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 4.3353e-04 - mae: 0.0215\n",
            "Epoch 171/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 4.1330e-04 - mae: 0.0208\n",
            "Epoch 172/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 4.0028e-04 - mae: 0.0203\n",
            "Epoch 173/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.8960e-04 - mae: 0.0199\n",
            "Epoch 174/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.8134e-04 - mae: 0.0197\n",
            "Epoch 175/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.7418e-04 - mae: 0.0194\n",
            "Epoch 176/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.6827e-04 - mae: 0.0192\n",
            "Epoch 177/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.6306e-04 - mae: 0.0190\n",
            "Epoch 178/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.5863e-04 - mae: 0.0188\n",
            "Epoch 179/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.5416e-04 - mae: 0.0186\n",
            "Epoch 180/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.5091e-04 - mae: 0.0185\n",
            "Epoch 181/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.4765e-04 - mae: 0.0184\n",
            "Epoch 182/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.4454e-04 - mae: 0.0183\n",
            "Epoch 183/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.4170e-04 - mae: 0.0182\n",
            "Epoch 184/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3920e-04 - mae: 0.0181\n",
            "Epoch 185/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3658e-04 - mae: 0.0180\n",
            "Epoch 186/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3447e-04 - mae: 0.0179\n",
            "Epoch 187/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3225e-04 - mae: 0.0179\n",
            "Epoch 188/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3016e-04 - mae: 0.0178\n",
            "Epoch 189/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.2841e-04 - mae: 0.0177\n",
            "Epoch 190/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.2642e-04 - mae: 0.0176\n",
            "Epoch 191/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.2473e-04 - mae: 0.0176\n",
            "Epoch 192/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.2326e-04 - mae: 0.0175\n",
            "Epoch 193/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.2141e-04 - mae: 0.0175\n",
            "Epoch 194/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1992e-04 - mae: 0.0174\n",
            "Epoch 195/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1849e-04 - mae: 0.0174\n",
            "Epoch 196/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1684e-04 - mae: 0.0173\n",
            "Epoch 197/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1537e-04 - mae: 0.0172\n",
            "Epoch 198/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1391e-04 - mae: 0.0172\n",
            "Epoch 199/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1239e-04 - mae: 0.0171\n",
            "Epoch 200/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.1115e-04 - mae: 0.0171\n",
            "Epoch 201/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.0990e-04 - mae: 0.0171\n",
            "Epoch 202/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.0857e-04 - mae: 0.0170\n",
            "Epoch 203/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0754e-04 - mae: 0.0170\n",
            "Epoch 204/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.0624e-04 - mae: 0.0169\n",
            "Epoch 205/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0503e-04 - mae: 0.0169\n",
            "Epoch 206/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0393e-04 - mae: 0.0168\n",
            "Epoch 207/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0313e-04 - mae: 0.0168\n",
            "Epoch 208/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 3.0189e-04 - mae: 0.0168\n",
            "Epoch 209/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0091e-04 - mae: 0.0168\n",
            "Epoch 210/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9978e-04 - mae: 0.0167\n",
            "Epoch 211/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9862e-04 - mae: 0.0167\n",
            "Epoch 212/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9774e-04 - mae: 0.0166\n",
            "Epoch 213/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9684e-04 - mae: 0.0166\n",
            "Epoch 214/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9586e-04 - mae: 0.0166\n",
            "Epoch 215/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9477e-04 - mae: 0.0165\n",
            "Epoch 216/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9397e-04 - mae: 0.0165\n",
            "Epoch 217/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9281e-04 - mae: 0.0165\n",
            "Epoch 218/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9179e-04 - mae: 0.0164\n",
            "Epoch 219/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9077e-04 - mae: 0.0164\n",
            "Epoch 220/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8988e-04 - mae: 0.0164\n",
            "Epoch 221/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8897e-04 - mae: 0.0163\n",
            "Epoch 222/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8815e-04 - mae: 0.0163\n",
            "Epoch 223/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8713e-04 - mae: 0.0163\n",
            "Epoch 224/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8617e-04 - mae: 0.0163\n",
            "Epoch 225/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8544e-04 - mae: 0.0162\n",
            "Epoch 226/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8474e-04 - mae: 0.0162\n",
            "Epoch 227/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8389e-04 - mae: 0.0162\n",
            "Epoch 228/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8300e-04 - mae: 0.0162\n",
            "Epoch 229/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8237e-04 - mae: 0.0161\n",
            "Epoch 230/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8194e-04 - mae: 0.0161\n",
            "Epoch 231/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8170e-04 - mae: 0.0161\n",
            "Epoch 232/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8194e-04 - mae: 0.0162\n",
            "Epoch 233/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8148e-04 - mae: 0.0161\n",
            "Epoch 234/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8196e-04 - mae: 0.0162\n",
            "Epoch 235/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8298e-04 - mae: 0.0163\n",
            "Epoch 236/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8589e-04 - mae: 0.0164\n",
            "Epoch 237/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8938e-04 - mae: 0.0166\n",
            "Epoch 238/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9580e-04 - mae: 0.0169\n",
            "Epoch 239/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0208e-04 - mae: 0.0172\n",
            "Epoch 240/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.1655e-04 - mae: 0.0180\n",
            "Epoch 241/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.3189e-04 - mae: 0.0185\n",
            "Epoch 242/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.6509e-04 - mae: 0.0199\n",
            "Epoch 243/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.9464e-04 - mae: 0.0208\n",
            "Epoch 244/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 4.8025e-04 - mae: 0.0236\n",
            "Epoch 245/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 5.4873e-04 - mae: 0.0253\n",
            "Epoch 246/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 7.0632e-04 - mae: 0.0285\n",
            "Epoch 247/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 7.2478e-04 - mae: 0.0288\n",
            "Epoch 248/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.1203e-04 - mae: 0.0315\n",
            "Epoch 249/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 7.3929e-04 - mae: 0.0287\n",
            "\n",
            "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 250/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 9.0523e-04 - mae: 0.0283\n",
            "Epoch 251/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 6.7174e-04 - mae: 0.0246\n",
            "Epoch 252/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 5.1376e-04 - mae: 0.0219\n",
            "Epoch 253/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 4.1661e-04 - mae: 0.0201\n",
            "Epoch 254/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.5830e-04 - mae: 0.0187\n",
            "Epoch 255/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.2432e-04 - mae: 0.0178\n",
            "Epoch 256/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 3.0419e-04 - mae: 0.0172\n",
            "Epoch 257/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.9236e-04 - mae: 0.0168\n",
            "Epoch 258/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.8530e-04 - mae: 0.0165\n",
            "Epoch 259/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.8088e-04 - mae: 0.0163\n",
            "Epoch 260/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7805e-04 - mae: 0.0162\n",
            "Epoch 261/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7611e-04 - mae: 0.0161\n",
            "Epoch 262/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.7473e-04 - mae: 0.0160\n",
            "Epoch 263/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7369e-04 - mae: 0.0159\n",
            "Epoch 264/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.7289e-04 - mae: 0.0159\n",
            "Epoch 265/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7226e-04 - mae: 0.0159\n",
            "Epoch 266/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.7172e-04 - mae: 0.0158\n",
            "Epoch 267/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7127e-04 - mae: 0.0158\n",
            "Epoch 268/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.7088e-04 - mae: 0.0158\n",
            "Epoch 269/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.7054e-04 - mae: 0.0158\n",
            "Epoch 270/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.7022e-04 - mae: 0.0158\n",
            "Epoch 271/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6994e-04 - mae: 0.0157\n",
            "Epoch 272/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6968e-04 - mae: 0.0157\n",
            "Epoch 273/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6944e-04 - mae: 0.0157\n",
            "Epoch 274/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6920e-04 - mae: 0.0157\n",
            "Epoch 275/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6898e-04 - mae: 0.0157\n",
            "Epoch 276/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6875e-04 - mae: 0.0157\n",
            "Epoch 277/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6855e-04 - mae: 0.0157\n",
            "Epoch 278/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6835e-04 - mae: 0.0157\n",
            "Epoch 279/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6816e-04 - mae: 0.0157\n",
            "Epoch 280/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6797e-04 - mae: 0.0156\n",
            "Epoch 281/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6778e-04 - mae: 0.0156\n",
            "Epoch 282/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6761e-04 - mae: 0.0156\n",
            "Epoch 283/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6744e-04 - mae: 0.0156\n",
            "Epoch 284/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6727e-04 - mae: 0.0156\n",
            "Epoch 285/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6710e-04 - mae: 0.0156\n",
            "Epoch 286/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6694e-04 - mae: 0.0156\n",
            "Epoch 287/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6678e-04 - mae: 0.0156\n",
            "Epoch 288/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6662e-04 - mae: 0.0156\n",
            "Epoch 289/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6647e-04 - mae: 0.0156\n",
            "Epoch 290/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6631e-04 - mae: 0.0156\n",
            "Epoch 291/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6617e-04 - mae: 0.0156\n",
            "Epoch 292/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6602e-04 - mae: 0.0156\n",
            "Epoch 293/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6588e-04 - mae: 0.0156\n",
            "Epoch 294/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6573e-04 - mae: 0.0155\n",
            "Epoch 295/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6559e-04 - mae: 0.0155\n",
            "Epoch 296/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6544e-04 - mae: 0.0155\n",
            "Epoch 297/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6530e-04 - mae: 0.0155\n",
            "Epoch 298/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 2.6517e-04 - mae: 0.0155\n",
            "Epoch 299/500\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 2.6502e-04 - mae: 0.0155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "ZnuGZcIaKLnP",
        "outputId": "27fc5eed-b3fa-4735-dbcc-5f619f40cfa3"
      },
      "source": [
        "history_frame.loc[:, ['loss']].plot()\n",
        "history_frame.loc[:, ['mae']].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfba64eb90>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGq1GDq5Nggr",
        "outputId": "b28f3a82-7a78-4867-9532-3e682463d90c"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 579ms/step - loss: 1.2433e-04 - mae: 0.0120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00012432815856300294, 0.011992981657385826]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzvY1klSN5To",
        "outputId": "57769331-28bf-4cff-fc2e-12cdaa20ab64"
      },
      "source": [
        "predictions = model.predict(test_dataset)\n",
        "predictions = scale_tesla_inv(predictions)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[734.4552 , 738.02234, 734.0108 , 743.52344, 752.8542 , 746.6237 ,\n",
              "        748.0897 ],\n",
              "       [730.7328 , 745.4376 , 745.6793 , 750.191  , 743.58813, 738.19885,\n",
              "        739.594  ],\n",
              "       [736.209  , 752.4539 , 755.5278 , 754.53864, 739.1384 , 736.03973,\n",
              "        735.63293],\n",
              "       [756.2965 , 748.65894, 750.53   , 742.8932 , 738.6454 , 741.7014 ,\n",
              "        734.9434 ],\n",
              "       [752.0996 , 748.06824, 746.5185 , 737.91833, 740.84424, 739.81494,\n",
              "        731.6907 ],\n",
              "       [755.14014, 734.5677 , 735.91833, 741.3956 , 743.20654, 748.7133 ,\n",
              "        748.0439 ],\n",
              "       [744.93567, 734.8906 , 737.6602 , 746.3336 , 751.4198 , 756.48364,\n",
              "        756.97626]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O29pQNA6N8hO",
        "outputId": "cd1d4727-1fc6-4e5a-c8a9-0a7307333c65"
      },
      "source": [
        "for x,y in test_dataset.take(1):\n",
        "  original = scale_tesla_inv(y.numpy())\n",
        "  print(original)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[733.57 733.57 733.57 752.92 753.87 754.86 736.27]\n",
            " [733.57 733.57 752.92 753.87 754.86 736.27 736.27]\n",
            " [733.57 752.92 753.87 754.86 736.27 736.27 736.27]\n",
            " [752.92 753.87 754.86 736.27 736.27 736.27 743.  ]\n",
            " [753.87 754.86 736.27 736.27 736.27 743.   744.49]\n",
            " [754.86 736.27 736.27 736.27 743.   744.49 755.83]\n",
            " [736.27 736.27 736.27 743.   744.49 755.83 756.99]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ZImiAxctHP-y",
        "outputId": "bc9be6b6-e41e-453b-a8d5-d136673deb76"
      },
      "source": [
        " err = pd.DataFrame(original - predictions)\n",
        " err"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.885200</td>\n",
              "      <td>-4.452339</td>\n",
              "      <td>-0.440803</td>\n",
              "      <td>9.396562</td>\n",
              "      <td>1.015813</td>\n",
              "      <td>8.236282</td>\n",
              "      <td>-11.819722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.837212</td>\n",
              "      <td>-11.867622</td>\n",
              "      <td>7.240679</td>\n",
              "      <td>3.679021</td>\n",
              "      <td>11.271865</td>\n",
              "      <td>-1.928853</td>\n",
              "      <td>-3.323994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.638984</td>\n",
              "      <td>0.466082</td>\n",
              "      <td>-1.657771</td>\n",
              "      <td>0.321365</td>\n",
              "      <td>-2.868428</td>\n",
              "      <td>0.230266</td>\n",
              "      <td>0.637065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.376509</td>\n",
              "      <td>5.211064</td>\n",
              "      <td>4.329971</td>\n",
              "      <td>-6.623188</td>\n",
              "      <td>-2.375386</td>\n",
              "      <td>-5.431416</td>\n",
              "      <td>8.056580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.770391</td>\n",
              "      <td>6.791763</td>\n",
              "      <td>-10.248494</td>\n",
              "      <td>-1.648335</td>\n",
              "      <td>-4.574238</td>\n",
              "      <td>3.185059</td>\n",
              "      <td>12.799326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.280137</td>\n",
              "      <td>1.702312</td>\n",
              "      <td>0.351665</td>\n",
              "      <td>-5.125630</td>\n",
              "      <td>-0.206543</td>\n",
              "      <td>-4.223318</td>\n",
              "      <td>7.786116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-8.665669</td>\n",
              "      <td>1.379375</td>\n",
              "      <td>-1.390217</td>\n",
              "      <td>-3.333618</td>\n",
              "      <td>-6.929800</td>\n",
              "      <td>-0.653643</td>\n",
              "      <td>0.013743</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0          1          2         3          4         5          6\n",
              "0 -0.885200  -4.452339  -0.440803  9.396562   1.015813  8.236282 -11.819722\n",
              "1  2.837212 -11.867622   7.240679  3.679021  11.271865 -1.928853  -3.323994\n",
              "2 -2.638984   0.466082  -1.657771  0.321365  -2.868428  0.230266   0.637065\n",
              "3 -3.376509   5.211064   4.329971 -6.623188  -2.375386 -5.431416   8.056580\n",
              "4  1.770391   6.791763 -10.248494 -1.648335  -4.574238  3.185059  12.799326\n",
              "5 -0.280137   1.702312   0.351665 -5.125630  -0.206543 -4.223318   7.786116\n",
              "6 -8.665669   1.379375  -1.390217 -3.333618  -6.929800 -0.653643   0.013743"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo-NXYl2IHRK",
        "outputId": "5e58d284-73a6-4fb8-9058-96d457a5596d"
      },
      "source": [
        "err.mean(axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.150085\n",
              "1    1.129758\n",
              "2   -0.787201\n",
              "3   -0.029841\n",
              "4    1.153639\n",
              "5    0.000638\n",
              "6   -2.797118\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUqc-AmWJfgT",
        "outputId": "75948628-07ce-44ed-ecca-4db72b6be512"
      },
      "source": [
        "err.std(axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7.274533\n",
              "1    7.612957\n",
              "2    1.548220\n",
              "3    5.791031\n",
              "4    7.556297\n",
              "5    4.240180\n",
              "6    3.735520\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVaCKE_AJym6",
        "outputId": "80c22227-cb25-4c79-efd4-e3800e7aa69a"
      },
      "source": [
        "err.apply(abs).mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2.922015\n",
              "1    4.552937\n",
              "2    3.665657\n",
              "3    4.303960\n",
              "4    4.177439\n",
              "5    3.412691\n",
              "6    6.348078\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIsWXg5AwQT9"
      },
      "source": [
        "model.save_weights('GRU_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFZV5YqP8Qo3",
        "outputId": "6e1a78bb-e10f-4357-9849-e550896315ea"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "scaler_filename = \"scaler.save\"\n",
        "joblib.dump(scaler, scaler_filename) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.save']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ]
}